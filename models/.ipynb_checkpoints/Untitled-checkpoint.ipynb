{
 "cells": [
  {
   "cell_type": "raw",
   "id": "73237959-a35b-4388-923a-7229b279016a",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fecc76ff-1a4d-41b6-8ac7-81a9332fdd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Model Training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Model Saving\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3d18b11-b8a0-4215-adc8-4942138734d0",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4443a748-5b3f-407e-9984-7f935c584c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\n\\n# Check if files exist\\nprint(\"Train file exists:\", os.path.exists(\"data/train.txt\"))\\nprint(\"Validation file exists:\", os.path.exists(\"data/val.txt\"))\\nprint(\"Test file exists:\", os.path.exists(\"data/test.txt\"))\\n\\nprint(\"Current working directory:\", os.getcwd())  # Show current directory\\n\\n# List files in the data folder\\nprint(\"Files in data folder:\", os.listdir(\"data\"))'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "\n",
    "# Check if files exist\n",
    "print(\"Train file exists:\", os.path.exists(\"data/train.txt\"))\n",
    "print(\"Validation file exists:\", os.path.exists(\"data/val.txt\"))\n",
    "print(\"Test file exists:\", os.path.exists(\"data/test.txt\"))\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())  # Show current directory\n",
    "\n",
    "# List files in the data folder\n",
    "print(\"Files in data folder:\", os.listdir(\"data\"))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fdcfd5e2-3f41-40ac-ad68-8d311b320d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "                                                 text  emotion\n",
      "0                            i didnt feel humiliated  sadness\n",
      "1  i can go from feeling so hopeless to so damned...  sadness\n",
      "2   im grabbing a minute to post i feel greedy wrong    anger\n",
      "3  i am ever feeling nostalgic about the fireplac...     love\n",
      "4                               i am feeling grouchy    anger \n",
      "\n",
      "Validation Data:\n",
      "                                                 text  emotion\n",
      "0  im feeling quite sad and sorry for myself but ...  sadness\n",
      "1  i feel like i am still looking at a blank canv...  sadness\n",
      "2                     i feel like a faithful servant     love\n",
      "3                  i am just feeling cranky and blue    anger\n",
      "4  i can have for a treat or if i am feeling festive      joy \n",
      "\n",
      "Test Data:\n",
      "                                                 text  emotion\n",
      "0  im feeling rather rotten so im not very ambiti...  sadness\n",
      "1          im updating my blog because i feel shitty  sadness\n",
      "2  i never make her separate from me because i do...  sadness\n",
      "3  i left with my bouquet of red and yellow tulip...      joy\n",
      "4    i was feeling a little vain when i did this one  sadness \n",
      "\n",
      "Train Set: 16000 samples\n",
      "Validation Set: 2000 samples\n",
      "Test Set: 2000 samples\n"
     ]
    }
   ],
   "source": [
    "# Load train, validation, and test datasets\n",
    "train_data = pd.read_csv(\"data/train.txt\", delimiter=\";\", header=None, names=[\"text\", \"emotion\"])\n",
    "val_data = pd.read_csv(\"data/val.txt\", delimiter=\";\", header=None, names=[\"text\", \"emotion\"])\n",
    "test_data = pd.read_csv(\"data/test.txt\", delimiter=\";\", header=None, names=[\"text\", \"emotion\"])\n",
    "\n",
    "# Print sample data from each set\n",
    "print(\"Train Data:\\n\", train_data.head(), \"\\n\")\n",
    "print(\"Validation Data:\\n\", val_data.head(), \"\\n\")\n",
    "print(\"Test Data:\\n\", test_data.head(), \"\\n\")\n",
    "\n",
    "# Check the size of each dataset\n",
    "print(f\"Train Set: {len(train_data)} samples\")\n",
    "print(f\"Validation Set: {len(val_data)} samples\")\n",
    "print(f\"Test Set: {len(test_data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5900f71b-05e4-4a65-908a-a2b6ef7c07e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         5362\n",
       "sadness     4666\n",
       "anger       2159\n",
       "fear        1937\n",
       "love        1304\n",
       "surprise     572\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f4d2de71-69b5-4ac8-829c-471f06904435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         695\n",
       "sadness     581\n",
       "anger       275\n",
       "fear        224\n",
       "love        159\n",
       "surprise     66\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8e2e2fa2-f0c5-4829-a313-c99a66121ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         704\n",
       "sadness     550\n",
       "anger       275\n",
       "fear        212\n",
       "love        178\n",
       "surprise     81\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "329c3a46-588b-4770-9987-e6daf77b838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Processing\n",
    "import neattext as nt\n",
    "import neattext.functions as nfx\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "aa844998-1157-49db-a5b9-ffe5668de91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['text'] = train_data['text'].apply(nfx.remove_userhandles)\n",
    "test_data['text'] = test_data['text'].apply(nfx.remove_userhandles)\n",
    "val_data['text'] = val_data['text'].apply(nfx.remove_userhandles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1bdd9ca0-77dc-4aac-9bcb-23e729ac94ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rraja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rraja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define stopwords set\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = nfx.remove_puncts(text)  # Remove punctuation\n",
    "    words = word_tokenize(text)  # Tokenization\n",
    "    text = \" \".join([word for word in words if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "train_data[\"text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "val_data[\"text\"] = val_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b35a56fe-191c-4837-ac7a-2a4bec8d7195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  emotion\n",
      "0                              didnt feel humiliated  sadness\n",
      "1  go feeling hopeless damned hopeful around some...  sadness\n",
      "2          im grabbing minute post feel greedy wrong    anger\n",
      "3  ever feeling nostalgic fireplace know still pr...     love\n",
      "4                                    feeling grouchy    anger\n",
      "                                                text  emotion\n",
      "0        im feeling rather rotten im ambitious right  sadness\n",
      "1                       im updating blog feel shitty  sadness\n",
      "2    never make separate ever want feel like ashamed  sadness\n",
      "3  left bouquet red yellow tulips arm feeling sli...      joy\n",
      "4                            feeling little vain one  sadness\n",
      "                                                text  emotion\n",
      "0           im feeling quite sad sorry ill snap soon  sadness\n",
      "1  feel like still looking blank canvas blank pie...  sadness\n",
      "2                         feel like faithful servant     love\n",
      "3                                feeling cranky blue    anger\n",
      "4                              treat feeling festive      joy\n"
     ]
    }
   ],
   "source": [
    "# Display cleaned text\n",
    "print(train_data.head())\n",
    "print(test_data.head())\n",
    "print(val_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "576392ec-69fe-4d59-9c5c-bcbd0f430f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convert text into TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Keep only the top 5000 words\n",
    "X_train = vectorizer.fit_transform(train_data[\"text\"])  # Fit and transform train data\n",
    "X_val = vectorizer.transform(val_data[\"text\"])  # Transform validation data\n",
    "X_test = vectorizer.transform(test_data[\"text\"])  # Transform test data\n",
    "\n",
    "# Target Variable (Emotion Labels)\n",
    "y_train = train_data[\"emotion\"]\n",
    "y_val = val_data[\"emotion\"]\n",
    "y_test = test_data[\"emotion\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7192549b-281d-4d08-9b77-e03a8c6af7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation data\n",
    "val_predictions = model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4b9d4e50-9260-4b54-85b4-ddf4e1a5a979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.90      0.84      0.87       275\n",
      "        fear       0.85      0.77      0.81       212\n",
      "         joy       0.87      0.95      0.91       704\n",
      "        love       0.89      0.72      0.80       178\n",
      "     sadness       0.88      0.94      0.91       550\n",
      "    surprise       0.86      0.62      0.72        81\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.88      0.81      0.83      2000\n",
      "weighted avg       0.88      0.88      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Check accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
    "\n",
    "# Show detailed performance report\n",
    "print(classification_report(y_val, val_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "752ad8d1-8c1a-4344-833b-027fdb8b8a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.88      0.89      0.89       275\n",
      "        fear       0.85      0.86      0.86       224\n",
      "         joy       0.89      0.94      0.91       695\n",
      "        love       0.79      0.72      0.75       159\n",
      "     sadness       0.93      0.91      0.92       581\n",
      "    surprise       0.73      0.62      0.67        66\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.85      0.82      0.83      2000\n",
      "weighted avg       0.88      0.89      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train SVM Model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5a6a6087-9c86-42ef-afaf-68b09e40edae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Random Forest Accuracy: 0.887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"📌 Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f70f7dcf-187a-428c-804c-9fb556b1b071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Naïve Bayes Accuracy: 0.754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Train Naïve Bayes Model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"📌 Naïve Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b03f4a34-3ab7-4969-b861-56072f042816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\pyhton3.11\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:40:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 XGBoost Accuracy: 0.889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Encode target labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Train XGBoost Model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Convert predictions back to original labels\n",
    "y_pred_xgb = label_encoder.inverse_transform(y_pred_xgb)\n",
    "\n",
    "# Evaluate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"📌 XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
